{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "from scipy.sparse import find\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "NUMCLASTERS = 15\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "       .builder \\\n",
    "       .master('yarn') \\\n",
    "       .enableHiveSupport() \\\n",
    "       .getOrCreate()\n",
    "\n",
    "#.master('yarn') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_W_FOR_PAGE_TYPE = {\"Card\" : 3,\n",
    "                        \"CardJK\" : 2,\n",
    "                        \"Listing\" : 1,\n",
    "                        \"ListingFavorites\" : 5}\n",
    "\n",
    "DICT_W_FOR_EVENT_TYPE = {\"card_show\" : 3,\n",
    "                        \"phone_show\" : 10}\n",
    "\n",
    "data=[('Card', 'card_show', int(DICT_W_FOR_PAGE_TYPE[\"Card\"] * DICT_W_FOR_EVENT_TYPE[\"card_show\"])), \n",
    "        ('CardJK', 'card_show', int(DICT_W_FOR_PAGE_TYPE[\"CardJK\"] * DICT_W_FOR_EVENT_TYPE[\"card_show\"])), \n",
    "        ('Listing', 'card_show', int(DICT_W_FOR_PAGE_TYPE[\"Listing\"] * DICT_W_FOR_EVENT_TYPE[\"card_show\"])), \n",
    "        ('ListingFavorites', 'card_show', int(DICT_W_FOR_PAGE_TYPE[\"ListingFavorites\"] * DICT_W_FOR_EVENT_TYPE[\"card_show\"])), \n",
    "        ('Card', 'phone_show', int(DICT_W_FOR_PAGE_TYPE[\"Card\"] * DICT_W_FOR_EVENT_TYPE[\"phone_show\"])), \n",
    "        ('CardJK', 'phone_show', int(DICT_W_FOR_PAGE_TYPE[\"CardJK\"] * DICT_W_FOR_EVENT_TYPE[\"phone_show\"])), \n",
    "        ('Listing', 'phone_show', int(DICT_W_FOR_PAGE_TYPE[\"Listing\"] * DICT_W_FOR_EVENT_TYPE[\"phone_show\"])), \n",
    "        ('ListingFavorites', 'phone_show', int(DICT_W_FOR_PAGE_TYPE[\"ListingFavorites\"] * DICT_W_FOR_EVENT_TYPE[\"phone_show\"]))]\n",
    "\n",
    "#spark.createDataFrame(data, ['page_type', 'event_type', 'value']).collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfdict = spark.createDataFrame(data, ['page_type', 'event_type', 'value'])\n",
    "dfdict.createOrReplaceTempView(\"dfdict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareRdd(x,y):\n",
    "    if (x['user_num'] > y['user_num']):\n",
    "        return x\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVector(x,y):\n",
    "    if type(x) is list:\n",
    "        if type(y) is list:\n",
    "            return x + y\n",
    "        elif type(y) is tuple:\n",
    "            return x + [y]\n",
    "        else: \n",
    "            raise BaseException('Wrong type of y')\n",
    "    elif type(x) is tuple:\n",
    "        if type(y) is list:\n",
    "            return [x] + y\n",
    "        elif type(y) is tuple:\n",
    "            return [x] + [y]\n",
    "        else: \n",
    "            raise BaseException('Wrong type of y')\n",
    "    else:\n",
    "        raise BaseException('Wrong type of x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortVector(a):\n",
    "    if type(a[1]) is list:\n",
    "        a[1].sort(key=lambda t: t[0])\n",
    "        #print(a)\n",
    "        b = []\n",
    "        c = []\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            #print(i)\n",
    "            if a[1][i][0] == a[1][i+1][0]:\n",
    "                if a[1][i][1] < a[1][i+1][1]:\n",
    "                    t = a[1].pop(i)\n",
    "                else:\n",
    "                    t = a[1].pop(i+1)\n",
    "                #print('pop', t)\n",
    "\n",
    "            else:\n",
    "                i = i + 1\n",
    "                b.append(a[1][i][0])\n",
    "                c.append(a[1][i][1])\n",
    "                #print('add', (a[1][i][0], a[1][i][1]) )\n",
    "            if i == len(a[1]) - 1:\n",
    "                break\n",
    "\n",
    "        return (a[0], (b, c))\n",
    "    elif type(a[1]) is tuple:\n",
    "        return (a[0], ([a[1][0]], [a[1][1]]))\n",
    "    else:\n",
    "        raise BaseException('Wrong type of a: ' + str(type(a[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = spark.sql(\"\"\"select user_id, offer_id, value from dfdict as a, prod.mles_sopr as b \n",
    "                            where a.page_type = b.page_type and a.event_type = b.event_type and user_id != 'noid'\n",
    "                        limit 10000\n",
    "                  \"\"\").repartition(100).createOrReplaceTempView(\"user_item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sql(\"\"\"select distinct a.offer_num, a.offer_id, b.user_num, b.user_id, c.value\n",
    "                    from user_item as c\n",
    "                         INNER JOIN (select row_number() OVER (ORDER BY a.user_id) as user_num, a.user_id \n",
    "                            from (select distinct user_id from user_item) as a) as b on c.user_id = b.user_id\n",
    "                         INNER JOIN (select row_number() OVER (ORDER BY a.offer_id) as offer_num, a.offer_id \n",
    "                            from (select distinct offer_id from user_item) as a) as a on c.offer_id = a.offer_id \n",
    "                        \"\"\") \\\n",
    "              .repartition(100).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxUserNum = rdd.reduce(lambda x, y: compareRdd(x,y))['user_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddKey = rdd.map(lambda x: (x['offer_num'], (x['user_num'], x['value']))) \n",
    "targetWithId = rddKey.reduceByKey(lambda x,y: createVector(x, y)) \\\n",
    "                     .map(lambda x: sortVector(x)) \\\n",
    "                     .map(lambda x: (x[0], Vectors.sparse(maxUserNum + 1, x[1][0], x[1][1])))\n",
    "\n",
    "target = targetWithId.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetSize = target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = target.randomSplit([(targetSize - 100)/targetSize, 100/targetSize])[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "MAX_K = 0\n",
    "STEP_K = 100\n",
    "cost = np.zeros(20)\n",
    "\n",
    "with tqdm.tqdm(total=20) as progress:\n",
    "    for i in range(20):\n",
    "        model = KMeans.train(X,\n",
    "                     i + 1, \n",
    "                     initializationMode=\"k-means||\", \n",
    "                     initializationSteps=5, \n",
    "                     epsilon=1e-4)\n",
    "        \n",
    "        cost[i] = model.computeCost(X)\n",
    "        print(i + 1, cost[i])\n",
    "        progress.update(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize =(12,10))\n",
    "plt.plot(np.arange(20) + 1, cost)\n",
    "\n",
    "plt.title('cost from num_klasters')\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('num_klasters')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans.train(X,\n",
    "                     NUMCLASTERS, \n",
    "                     initializationMode=\"k-means||\", \n",
    "                     initializationSteps=5, \n",
    "                     epsilon=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addpredict(x):\n",
    "    #print('It works!')\n",
    "    p = model.predict(x[1])\n",
    "    #print(p)\n",
    "    return (x[0], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetWithIdPred = targetWithId.map(lambda x: addpredict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "listrdd = [spark.createDataFrame(targetWithIdPred.filter(lambda x: x[1] == i) \\\n",
    "                                                 .join(rdd.map(lambda x: (x['offer_num'], x))) \\\n",
    "                                                 .map(lambda x: x[1][1])) \n",
    "           for i in range(NUMCLASTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoolALS(x):\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"user_num\", itemCol=\"offer_id\", ratingCol=\"value\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "    model = als.fit(x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:33<00:00,  5.95s/it]\n"
     ]
    }
   ],
   "source": [
    "modelList = []\n",
    "recsList = []\n",
    "with tqdm.tqdm(total=NUMCLASTERS) as progress:\n",
    "    for i in range(NUMCLASTERS):\n",
    "        model = PoolALS(listrdd[i])\n",
    "        modelList.append(model)\n",
    "        user_recs = model.recommendForAllUsers(3)\n",
    "        recsList.append(user_recs)\n",
    "        progress.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
